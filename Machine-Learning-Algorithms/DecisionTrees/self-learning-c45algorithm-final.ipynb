{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator\n",
    "import treePlotter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data\n",
    "数据集有四个特征 'outlook', 'temperature', 'humidity', 'windy'，\n",
    "接下来要计算它们的信息增益率，来选择节点的构成方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    \"\"\"\n",
    "    outlook->  0: sunny | 1: overcast | 2: rain\n",
    "    temperature-> 0: hot | 1: mild | 2: cool\n",
    "    humidity-> 0: high | 1: normal\n",
    "    windy-> 0: false | 1: true \n",
    "    \"\"\"\n",
    "    dataSet = [[0, 0, 0, 0, 'N'], \n",
    "               [0, 0, 0, 1, 'N'], \n",
    "               [1, 0, 0, 0, 'Y'], \n",
    "               [2, 1, 0, 0, 'Y'], \n",
    "               [2, 2, 1, 0, 'Y'], \n",
    "               [2, 2, 1, 1, 'N'], \n",
    "               [1, 2, 1, 1, 'Y']]\n",
    "    labels = ['outlook', 'temperature', 'humidity', 'windy']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"\n",
    "    输入：数据集\n",
    "    输出：数据集的香农熵\n",
    "    描述：计算给定数据集的香农熵；熵越大，数据集的混乱程度越大\n",
    "    \"\"\"\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1      # 数每一类各多少个， {'Y': 4, 'N': 3}\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries  # 4/7 3/7\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    \"\"\"\n",
    "    输入：分类类别列表\n",
    "    输出：子节点的分类\n",
    "    描述：数据集已经处理了所有属性，但是类标签依然不是唯一的，\n",
    "          采用多数判决的方法决定该子节点的分类\n",
    "    \"\"\"\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reversed=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择最大的gain ratio对应的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    \"\"\"\n",
    "    输入：数据集\n",
    "    输出：最好的划分维度\n",
    "    描述：选择最好的数据集划分维度\n",
    "    \"\"\"\n",
    "    numFeatures = len(dataSet[0]) - 1                 #feature个数\n",
    "    baseEntropy = calcShannonEnt(dataSet)             #整个dataset的熵\n",
    "    bestInfoGainRatio = 0.0\n",
    "    bestFeature = -1\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet]  #每个feature的list\n",
    "        uniqueVals = set(featList)                      #每个list的唯一值集合                 \n",
    "        newEntropy = 0.0\n",
    "        splitInfo = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)  #每个唯一值对应的剩余feature的组成子集\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "            splitInfo += -prob * log(prob, 2)\n",
    "        infoGain = baseEntropy - newEntropy              #这个feature的infoGain\n",
    "        if (splitInfo == 0): # fix the overflow bug\n",
    "            continue\n",
    "        infoGainRatio = infoGain / splitInfo             #这个feature的infoGainRatio      \n",
    "        if (infoGainRatio > bestInfoGainRatio):          #选择最大的gain ratio\n",
    "            bestInfoGainRatio = infoGainRatio\n",
    "            bestFeature = i                              #选择最大的gain ratio对应的feature\n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据，为下一层计算准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    \"\"\"\n",
    "    输入：数据集，选择维度，选择值\n",
    "    输出：划分数据集\n",
    "    描述：按照给定特征划分数据集；去除选择维度中等于选择值的项\n",
    "    \"\"\"\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:                      #只看当第i列的值＝value时的item\n",
    "            reduceFeatVec = featVec[:axis]              #featVec的第i列给除去\n",
    "            reduceFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reduceFeatVec)            \n",
    "    return retDataSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多重字典构建树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTree(dataSet, labels):\n",
    "    \"\"\"\n",
    "    输入：数据集，特征标签\n",
    "    输出：决策树\n",
    "    描述：递归构建决策树，利用上述的函数\n",
    "    \"\"\"\n",
    "    classList = [example[-1] for example in dataSet]         # ['N', 'N', 'Y', 'Y', 'Y', 'N', 'Y']\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        # classList所有元素都相等，即类别完全相同，停止划分\n",
    "        return classList[0]                                  #splitDataSet(dataSet, 0, 0)此时全是N，返回N\n",
    "    if len(dataSet[0]) == 1:                                 #[0, 0, 0, 0, 'N'] \n",
    "        # 遍历完所有特征时返回出现次数最多的\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)             #0－> 2   \n",
    "        # 选择最大的gain ratio对应的feature\n",
    "    bestFeatLabel = labels[bestFeat]                         #outlook -> windy     \n",
    "    myTree = {bestFeatLabel:{}}                   \n",
    "        #多重字典构建树{'outlook': {0: 'N'\n",
    "    del(labels[bestFeat])                                    #['temperature', 'humidity', 'windy'] -> ['temperature', 'humidity']        \n",
    "    featValues = [example[bestFeat] for example in dataSet]  #[0, 0, 1, 2, 2, 2, 1]     \n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]                                #['temperature', 'humidity', 'windy']\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "            # 划分数据，为下一层计算准备\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化决策树的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 'N'], [0, 0, 0, 1, 'N'], [1, 0, 0, 0, 'Y'], [2, 1, 0, 0, 'Y'], [2, 2, 1, 0, 'Y'], [2, 2, 1, 1, 'N'], [1, 2, 1, 1, 'Y']]\n",
      "['outlook', 'temperature', 'humidity', 'windy']\n",
      "{'outlook': {0: 'N', 1: 'Y', 2: {'windy': {0: 'Y', 1: 'N'}}}}\n",
      "3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'keys'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-4d79f477b4d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdesicionTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdesicionTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'children'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'children'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtreePlotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreatePlot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesicionTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Workplace\\python\\Learning-Notes\\Machine-Learning-Algorithms\\DecisionTrees\\treePlotter.py\u001b[0m in \u001b[0;36mcreatePlot\u001b[1;34m(inTree)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0maxprops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mcreatePlot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframeon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0maxprops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mplotTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotalw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetNumLeafs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[0mplotTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotalD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetTreeDepth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mplotTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxOff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mplotTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotalw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Workplace\\python\\Learning-Notes\\Machine-Learning-Algorithms\\DecisionTrees\\treePlotter.py\u001b[0m in \u001b[0;36mgetNumLeafs\u001b[1;34m(myTree)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0msecondDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyTree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirstStr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0msecondDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msecondDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecondDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'dict'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mnumLeafs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgetNumLeafs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecondDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'keys'"
     ],
     "output_type": "error"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA19JREFUeJzt1DEBACAMwDDAv+dxIIIeiYJe3TMzC4Dvzu8AAB5DBogw\nZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBk\ngAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSA\nCEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAI\nQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhD\nBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMG\niDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaI\nMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogw\nZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBk\ngAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSA\nCEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAI\nQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhD\nBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMG\niDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaI\nMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogwZIAIQwaIMGSACEMGiDBkgAhDBogw\nZIAIQwaIMGSACEMGiDBkgAhDBogwZICIC8zwBdi9xYGPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x90a1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataSet, labels = createDataSet()\n",
    "labels_tmp = labels[:]\n",
    "desicionTree = createTree(dataSet, labels_tmp)\n",
    "print dataSet\n",
    "print labels\n",
    "print desicionTree\n",
    "desicionTree = \\\n",
    "{'id': 3, 'children': [{'id': 2, 'children': [{'id': 1}, {'id': 4}]}, {'id': 5}]}\n",
    "# {'\\xe7\\x9b\\xb4\\xe9\\x80\\x9a\\xe8\\xbd\\xa6\\xe9\\x94\\x80\\xe5\\x94\\xae\\xe9\\x87\\x91\\xe9\\xa2\\x9d\\xe6\\x95\\xb0\\xe6\\x8d\\xae\\xe5\\x88\\x86\\xe6\\x9e\\x90': {41L: {41: {42L: {42: {44L: {44: {46L: {46: {48L: {48: '\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe6\\x96\\xb0\\xe5\\xa2\\x9e\\xe6\\x8a\\x95\\xe6\\x94\\xbe\\xe5\\xae\\xa2\\xe6\\x88\\xb7'}, 49L: {49: '\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe4\\xb8\\x8b\\xe7\\xba\\xbf\\xe5\\xae\\xa2\\xe6\\x88\\xb7'}, 50L: {50: '\\xe5\\x9f\\xba\\xe6\\x9c\\x9f\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe6\\x8a\\x95\\xe6\\x94\\xbe\\xe5\\xae\\xa2\\xe6\\x88\\xb7'}}}, 47L: {47: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}, 45L: {45: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}, 43L: {43: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}, 51L: {51: {52L: {52: {54L: {54: {56L: {56: {58L: {58: '\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe6\\x96\\xb0\\xe5\\xa2\\x9e\\xe6\\x8a\\x95\\xe6\\x94\\xbe\\xe5\\xae\\xa2\\xe6\\x88\\xb7'}, 59L: {59: '\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe4\\xb8\\x8b\\xe7\\xba\\xbf\\xe5\\xae\\xa2\\xe6\\x88\\xb7'}, 60L: {60: '\\xe5\\x9f\\xba\\xe6\\x9c\\x9f\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe6\\x8a\\x95\\xe6\\x94\\xbe\\xe5\\xae\\xa2\\xe6\\x88\\xb7'}}}, 57L: {57: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}, 55L: {55: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}, 53L: {53: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}, 15L: {15: {16L: {16: {18L: {18: {20L: {20: {24L: {24: '\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe6\\x96\\xb0\\xe5\\xa2\\x9e\\xe6\\x8a\\x95\\xe6\\x94\\xbe\\xe5\\xae\\xa2\\xe6\\x88\\xb7'}, 25L: {25: '\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe4\\xb8\\x8b\\xe7\\xba\\xbf\\xe5\\xae\\xa2\\xe6\\x88\\xb7'}, 26L: {26: {31L: {31: {32L: {32: {34L: {34: {36L: {36: {38L: {38: '\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe4\\xb8\\x8b\\xe7\\xba\\xbf'}, 39L: {39: '\\xe5\\x9f\\xba\\xe6\\x9c\\x9f\\xe6\\x9c\\xac\\xe6\\x9c\\x9f\\xe6\\x8a\\x95\\xe6\\x94\\xbe'}}}, 37L: {37: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2\\xe5\\x8f\\xaf\\xe6\\x8f\\x90\\xe5\\x8d\\x87\\xe7\\x82\\xb9\\xe6\\x9f\\xa5\\xe6\\x89\\xbe'}}}, 35L: {35: '\\xe5\\xae\\xa2\\xe6\\x88\\xb7\\xe7\\xab\\x9e\\xe4\\xbb\\xb7\\xe9\\x87\\x8f\\xe4\\xb8\\x8b\\xe9\\x99\\x8d\\xef\\xbc\\x8c\\xe5\\xbb\\xba\\xe8\\xae\\xae\\xe6\\x8b\\x93\\xe5\\xb1\\x95\\xe5\\x85\\xb3\\xe9\\x94\\xae\\xe8\\xaf\\x8d\\xef\\xbc\\x8c\\xe6\\x81\\xa2\\xe5\\xa4\\x8d\\xe5\\x90\\x8e\\xe9\\xa2\\x84\\xe8\\xae\\xa1\\xe6\\x94\\xb6\\xe5\\x85\\xa5\\xe5\\x8f\\xaf\\xe6\\x8f\\x90\\xe5\\x8d\\x87%s\\xe5\\x85\\x83'}}}, 33L: {33: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}}}}}, 21L: {21: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}, 19L: {19: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}, 17L: {17: '\\xe5\\x81\\x9c\\xe6\\xad\\xa2'}}}}}\n",
    "treePlotter.createPlot(desicionTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对新数据进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(inputTree, featLabels, testVec):\n",
    "    \"\"\"\n",
    "    输入：决策树，分类标签，测试数据\n",
    "    输出：决策结果\n",
    "    描述：跑决策树\n",
    "    \"\"\"\n",
    "\n",
    "    firstStr = list(inputTree.keys())[0]                       # ['outlook'], outlook\n",
    "    secondDict = inputTree[firstStr]                           # {0: 'N', 1: 'Y', 2: {'windy': {0: 'Y', 1: 'N'}}}\n",
    "    featIndex = featLabels.index(firstStr)                     # outlook所在的列序号0 \n",
    "    for key in secondDict.keys():                              # secondDict.keys()＝[0, 1, 2]\n",
    "        if testVec[featIndex] == key:                          # secondDict[key]＝N\n",
    "            # test向量的当前feature是哪个值，就走哪个树杈\n",
    "            if type(secondDict[key]).__name__ == 'dict':       # type(secondDict[key]).__name__＝str\n",
    "                # 如果secondDict[key]仍然是字典，则继续向下层走\n",
    "                classLabel = classify(secondDict[key], featLabels, testVec)\n",
    "            else:\n",
    "                # 如果secondDict[key]已经只是分类标签了，则返回这个类别标签\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Test Set\n",
    "def createTestSet():\n",
    "    \"\"\"\n",
    "    outlook->  0: sunny | 1: overcast | 2: rain\n",
    "    temperature-> 0: hot | 1: mild | 2: cool\n",
    "    humidity-> 0: high | 1: normal\n",
    "    windy-> 0: false | 1: true \n",
    "    \"\"\"\n",
    "    testSet = [[0, 1, 0, 0], \n",
    "               [0, 2, 1, 0], \n",
    "               [2, 1, 1, 0], \n",
    "               [0, 1, 1, 1], \n",
    "               [1, 1, 0, 1], \n",
    "               [1, 0, 1, 0], \n",
    "               [2, 1, 0, 1]]\n",
    "    return testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'\\xe7\\x9b\\xb4\\xe9\\x80\\x9a\\xe8\\xbd\\xa6\\xe9\\x94\\x80\\xe5\\x94\\xae\\xe9\\x87\\x91\\xe9\\xa2\\x9d\\xe6\\x95\\xb0\\xe6\\x8d\\xae\\xe5\\x88\\x86\\xe6\\x9e\\x90' is not in list",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4f6b6eecabe3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeatLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'outlook'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'temperature'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'humidity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'windy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtestVec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestVec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-1a3701b53878>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(inputTree, featLabels, testVec)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mfirstStr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m                       \u001b[1;31m# ['outlook'], outlook\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msecondDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputTree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirstStr\u001b[0m\u001b[1;33m]\u001b[0m                           \u001b[1;31m# {0: 'N', 1: 'Y', 2: {'windy': {0: 'Y', 1: 'N'}}}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mfeatIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatLabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirstStr\u001b[0m\u001b[1;33m)\u001b[0m                     \u001b[1;31m# outlook所在的列序号0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msecondDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                              \u001b[1;31m# secondDict.keys()＝[0, 1, 2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtestVec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatIndex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m                          \u001b[1;31m# secondDict[key]＝N\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: '\\xe7\\x9b\\xb4\\xe9\\x80\\x9a\\xe8\\xbd\\xa6\\xe9\\x94\\x80\\xe5\\x94\\xae\\xe9\\x87\\x91\\xe9\\xa2\\x9d\\xe6\\x95\\xb0\\xe6\\x8d\\xae\\xe5\\x88\\x86\\xe6\\x9e\\x90' is not in list"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "inputTree = desicionTree\n",
    "featLabels = ['outlook', 'temperature', 'humidity', 'windy']\n",
    "testVec = [0, 1, 0, 0]\n",
    "classify(inputTree, featLabels, testVec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对多条新数据进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyAll(inputTree, featLabels, testDataSet):\n",
    "    \"\"\"\n",
    "    输入：决策树，分类标签，测试数据集\n",
    "    输出：决策结果\n",
    "    描述：跑决策树\n",
    "    \"\"\"\n",
    "    classLabelAll = []\n",
    "    for testVec in testDataSet:               #逐个item进行分类判断\n",
    "        classLabelAll.append(classify(inputTree, featLabels, testVec))\n",
    "    return classLabelAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('classifyResult:\\n', ['N', 'N', 'Y', 'N', 'Y', 'Y', 'N'])\n"
     ]
    }
   ],
   "source": [
    "testSet = createTestSet()\n",
    "print('classifyResult:\\n', classifyAll(desicionTree, labels, testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
